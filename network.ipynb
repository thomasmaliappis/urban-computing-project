{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cfc2c03",
      "metadata": {
        "id": "8cfc2c03"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, Concatenate\n",
        "\n",
        "from keras.regularizers import l1_l2\n",
        "from tensorflow import keras\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6daf88d6",
      "metadata": {
        "id": "6daf88d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d6c29a",
      "metadata": {
        "id": "08d6c29a"
      },
      "outputs": [],
      "source": [
        "path_images=\"./images.npz\"\n",
        "path_cities=\"./cities.npz\"\n",
        "path_class=\"./classes.npz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6217fce5",
      "metadata": {
        "id": "6217fce5"
      },
      "outputs": [],
      "source": [
        "from numpy import load\n",
        "dict_image_data = load(path_images)\n",
        "image_data = dict_image_data['arr_0']\n",
        "dict_class_data = load(path_class)\n",
        "class_data = dict_class_data['arr_0']\n",
        "dict_city_data = load(path_cities)\n",
        "city_data = dict_city_data['arr_0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b26d7e81",
      "metadata": {
        "id": "b26d7e81"
      },
      "outputs": [],
      "source": [
        "# all 512 images resized to 128\n",
        "data_512 = image_data[:,0]\n",
        "# all 512 images cropped to 256 images and resized to 128\n",
        "data_256 = image_data[:,1]\n",
        "# all 512 images cropped to 128 images\n",
        "data_128 = image_data[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4ea8ab",
      "metadata": {
        "id": "1d4ea8ab",
        "outputId": "2cc449ab-9445-473b-cac3-a35fd1ad8eb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((28195,), (28195, 128, 128, 3), (28195, 3, 128, 128, 3))"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "city_data.shape, data_512.shape, image_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174eccec",
      "metadata": {
        "id": "174eccec",
        "outputId": "4a203ea5-0163-48e4-9573-da4b91dcee5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.unique(class_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e17fa0",
      "metadata": {
        "id": "a8e17fa0"
      },
      "source": [
        "### Tranformation of labels to onehot decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "397d73e7",
      "metadata": {
        "id": "397d73e7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "label_as_binary = LabelBinarizer()\n",
        "\n",
        "train__y_labels_city = label_as_binary.fit_transform(city_data)\n",
        "train__y_labels_class = label_as_binary.fit_transform(class_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f1a6b7",
      "metadata": {
        "id": "09f1a6b7"
      },
      "source": [
        "### Split the data set to train and test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71bca9c0",
      "metadata": {
        "id": "71bca9c0"
      },
      "outputs": [],
      "source": [
        "#City\n",
        "train_X_512_ci,valid_X_512_ci,train_label_512_ci,valid_label_512_ci = train_test_split(data_512, train__y_labels_city, test_size=0.3)\n",
        "train_X_256_ci,valid_X_256_ci,train_label_256_ci,valid_label_256_ci = train_test_split(data_256, train__y_labels_city, test_size=0.3)\n",
        "train_X_128_ci,valid_X_128_ci,train_label_128_ci,valid_label_128_ci = train_test_split(data_128, train__y_labels_city, test_size=0.3)\n",
        "\n",
        "\n",
        "#Class\n",
        "train_X_512_cl,valid_X_512_cl,train_label_512_cl,valid_label_512_cl = train_test_split(data_512, train__y_labels_class, test_size=0.3)\n",
        "train_X_256_cl,valid_X_256_cl,train_label_256_cl,valid_label_256_cl = train_test_split(data_256, train__y_labels_class, test_size=0.3)\n",
        "train_X_128_cl,valid_X_128_cl,train_label_128_cl,valid_label_128_cl = train_test_split(data_128, train__y_labels_class, test_size=0.3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc54a39f",
      "metadata": {
        "id": "bc54a39f"
      },
      "outputs": [],
      "source": [
        "#approach 2 for splitting\n",
        "x_train_comp = np.stack([data_512,data_256,data_128], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04aa216e",
      "metadata": {
        "id": "04aa216e"
      },
      "outputs": [],
      "source": [
        "x_train_city, x_test_city, y_train_city, y_test_city = train_test_split(x_train_comp, train__y_labels_city, test_size = 0.3)\n",
        "x_train_class, x_test_claa, y_train_class, y_test_class = train_test_split(x_train_comp, train__y_labels_class, test_size = 0.3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621d513b",
      "metadata": {
        "id": "621d513b"
      },
      "source": [
        "#### Test of models individually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415874dd",
      "metadata": {
        "id": "415874dd"
      },
      "outputs": [],
      "source": [
        "#test of model using data_512 and city clasiification\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu', input_shape=(128, 128, 3)))\n",
        "model_1.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model_1.add(MaxPooling2D((2,2)))  \n",
        "model_1.add(Dropout(0.1)) \n",
        "model_1.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model_1.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model_1.add(MaxPooling2D((2,2)))\n",
        "model_1.add(Dropout(0.1))\n",
        "model_1.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model_1.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D((2,2)))\n",
        "model_1.add(Dropout(0.1))\n",
        "model_1.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model_1.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model_1.add(MaxPooling2D((4,4)))\n",
        "model_1.add(Dropout(0.1))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(1024, activation='relu'))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0cdac61",
      "metadata": {
        "id": "f0cdac61",
        "outputId": "8492055f-2657-4801-f8ad-640528ce9359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28195/28195 [==============================] - 2939s 104ms/step - loss: 1.6709 - accuracy: 0.2773\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe32fbaaee0>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_1.fit(data_512, train__y_labels_city, batch_size=1, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e85913",
      "metadata": {
        "id": "99e85913"
      },
      "source": [
        "### Creating three models with three different inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1543b142",
      "metadata": {
        "id": "1543b142"
      },
      "outputs": [],
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu', input_shape=(128, 128, 3)))\n",
        "model_1.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model_1.add(MaxPooling2D((2,2)))  \n",
        "model_1.add(Dropout(0.1)) \n",
        "model_1.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model_1.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model_1.add(MaxPooling2D((2,2)))\n",
        "model_1.add(Dropout(0.1))\n",
        "model_1.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model_1.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D((2,2)))\n",
        "model_1.add(Dropout(0.1))\n",
        "model_1.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model_1.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model_1.add(MaxPooling2D((4,4)))\n",
        "model_1.add(Dropout(0.1))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(1024, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_2 = Sequential()\n",
        "model_2.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu', input_shape=(128, 128, 3)))\n",
        "model_2.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model_2.add(MaxPooling2D((2,2)))  \n",
        "model_2.add(Dropout(0.1)) \n",
        "model_2.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model_2.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model_2.add(MaxPooling2D((2,2)))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model_2.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D((2,2)))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model_2.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model_2.add(MaxPooling2D((4,4)))\n",
        "model_2.add(Dropout(0.1))\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(1024, activation='relu'))\n",
        "\n",
        "\n",
        "model_3 = Sequential()\n",
        "model_3.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu', input_shape=(128, 128, 3)))\n",
        "model_3.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model_3.add(MaxPooling2D((2,2)))  \n",
        "model_3.add(Dropout(0.1)) \n",
        "model_3.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model_3.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model_3.add(MaxPooling2D((2,2)))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model_3.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(MaxPooling2D((2,2)))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model_3.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model_3.add(MaxPooling2D((4,4)))\n",
        "model_3.add(Dropout(0.1))\n",
        "\n",
        "model_3.add(Flatten())\n",
        "model_3.add(Dense(1024, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5076bea0",
      "metadata": {
        "id": "5076bea0"
      },
      "source": [
        "### Concatenate three models into one dense vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87aff582",
      "metadata": {
        "id": "87aff582"
      },
      "outputs": [],
      "source": [
        "Concatenated = Concatenate([model_1.outputs[0], model_2.outputs[0],model_3.outputs[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89974d5f",
      "metadata": {
        "id": "89974d5f"
      },
      "outputs": [],
      "source": [
        "#City\n",
        "model_classifier1 = Sequential()\n",
        "model_classifier1.add(Concatenated)\n",
        "model_classifier1.add(Flatten())\n",
        "model_classifier1.add(Dense(2048, activation='relu'))\n",
        "model_classifier1.add(Dropout(0.1))\n",
        "model_classifier1.add(Dense(5, activation='softmax'))\n",
        "\n",
        "#Class\n",
        "model_classifier2 = Sequential()\n",
        "model_classifier2.add(Concatenated)\n",
        "model_classifier2.add(Flatten())\n",
        "model_classifier2.add(Dense(2048, activation='relu'))\n",
        "model_classifier2.add(Dropout(0.1))\n",
        "model_classifier2.add(Dense(18, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c57546c",
      "metadata": {
        "id": "4c57546c"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n",
        "\n",
        "#City\n",
        "model_classifier1.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['f1_m'])\n",
        "#Class\n",
        "model_classifier2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['f1_m'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55e79ff7",
      "metadata": {
        "id": "55e79ff7",
        "outputId": "e60e0d11-5378-4634-abe2-df1561d6ac68"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/merge.py\", line 498, in build\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_78\" (type Sequential).\n    \n    A `Concatenate` layer should be called on a list of at least 1 input. Received: input_shape=(1, 3, 128, 128, 3)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(1, 3, 128, 128, 3), dtype=uint8)\n      • training=True\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-1dad85458493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_classifier1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain__y_labels_city\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/merge.py\", line 498, in build\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_78\" (type Sequential).\n    \n    A `Concatenate` layer should be called on a list of at least 1 input. Received: input_shape=(1, 3, 128, 128, 3)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(1, 3, 128, 128, 3), dtype=uint8)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "model_classifier1.fit(x_train_comp, train__y_labels_city, batch_size=1, epochs=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc9a14e",
      "metadata": {
        "id": "3cc9a14e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow_env",
      "language": "python",
      "name": "tensorflow_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
